
\begin{document}

\chapter{Background}

\label{chapter:background}

This chapter will review the the state of the art people detection and tracking techniques.

Tracking by detection is a popular appraoch to tracking objects in complex environments. A tracking by detection algorithm would detect interested objects in every frame update, thus updating the tracks in the internal of the algorithm. Tracking based on corrleation or changed-based matching between frames introduces new challenges, such as stochastic movements, sensor noise, illumination changes, cluttered and dynamic backgrounds, and occlusion. Current tracking methods combine this simple approach and predictions about object trajectory to achieve better results. Kalman Filter is the fundamental building block of many tracking algorithms for predicting the states of the objects in the scene. Other variations of the Kalman Filter include the Extended Kalman Filter~\cite{ljung_extended_kalman} and Unscented Kalman Filter~\cite{julier_unscented_kalman}.

The problem of people detection and tracking has been researched extensively in surveillance video, using techniques such as particle filters~\cite{sherrah_particle_filter_video_surveillance}, background subtraction techniques and color histograms~\cite{mckenna_tracking_groups_of_people}, 3D pose estimation~\cite{andriluka_3d_pose_estimation_tracking}, occlusion-aware people dectors~\cite{tang_people_dectector}, and clustering the motion paths of local features~\cite{gudys_cluster_local_features}.

With the advent of inexpensive, time-of-flight cameras like the Kinect, various tracking algorithms have taken the advantage of high frame rates depth and RGB data. They are portable and easily depolyable in real world environments.

\section{Tracking with Kinect}

This section describes a number of different methodologies of tracking people using the Kinect in recent research. Tracking with RGB-D cameras such as the Kinect usually uses both the color and depth information. In general, color information is great at distinguishing people who look somewhat different, using local features or gradient orientations from the body region. However, color information can fail to track people correctly when the occlusion is severe. On the other hand, depth information is great at segmenting a cluster of people based on their depth values and the derived height values. This is important because people may not have persistence color and texture when they move about in the environment or interact with others. The next two paragraphs will review some common techniques in tracking with color and depth information.

Color normalization and histograms are common techniques in RGB-based tracking. The distribution of color values in an image may change accordingly to the illumination level in the environment when the image was taken. Color normalization can migitate this unwanted effect~\cite{reinhard_color_transfers}. Some studies use other color spaces for tracking purposes. For instance, Liu et al.\ uses the hue component in the HSV color space to minize the effects of illumination~\cite{liu_tracking_with_pei}.

Color histograms represent an image by showing the the amount of pixels each range of color values occupies in that image. Correlation or intersection of two histograms can be used in similarity matching between tracks. In particular, histogram of oriented gradients (HOG) is a power feature descriptor for tracking similar tragets~\cite{dalal_hog, dollar_pedestrian_detection, munaro_tracking_within_groups_with_mobile_robot, luber_rgbd_boosted_models}. An image gradient is a directional change in the color intensity of a fixed-size detection window. Each detection window is divided into cells. A local histogram of gradient directions is created for each cell, hence local features can be characterized by the distribution of the local gradients. The descriptor can be used to train a linear Support Vector Machine (SVM) to do person and non-person classification, as well as to detect multiple people with a discriminative appearance model.

Depth-based tracking makes detection decisions using the technique of segmentation. 


% Plagemann et al proposes an interest points detector to identify different body parts in depth images [21]. Ikemura and Fujiyoshi perform people detection using similarity features from local depth histograms[22]. Other discriminative models detect people using directional changes in depth map [5] and incorporating multiple sensor inputs [17].

% Xia et al proposes a generative method for people tracking using depth information from the Kinect [19]. Initially, the proposed method uses the nearest neighbor interpolation algorithm to fill missing depth data with similar values to the neighbors. It also applies a median filter on the depth array to smooth the depth pixels. Then, a process known as 2D chamfer distance matching is used to find regions that may contain a person by using edge information in the depth array. The method translate and position a head template to match it against the resulting edge map of the selected regions. A 2-D head contour model and a 3-D head surface models are used to differentiate whether a region is actually a head. The whole body contours are then extracted using a region growing algorithm. This allows the tracked body to be segmented from other objects nearby. Color-based tracking is performed based on the assumption that an object would have similar RGB values in successive time frames. On the other hand, depth-based tracking measures the movements of the objects in 3-D space. The method assume that the coordinates and speed of each detected person change slowly, hence the tracking is performed by matching targets with the least energy scores.

\subsection{Subclustering and appearance classifiers}

Munaro et al.\ proposes a people tracking algorithm for mobile robots using depth sensor information~\cite{munaro_tracking_within_groups_with_mobile_robot}. The proposed algoritm performs clustering on the scene for initial detection, then uses Kalman filter on the motion and appearance features to track multiple people within groups. The method assumes people are on the ground plane.

Initially, the method reduces the size of the Kinect depth point cloud through voxel grid filtering. The process divides the depth map into voxels, where the value of each voxel is the averaged depth value over an area. Then, depth clustering is used to segment the scene in to potential people with different heights. Sub clusters are created by finding the local maxima inside the entire cluster, where each sub-cluster is a bounding box enclosing a person's body. A HOG confidence is calculated for every sub-cluster, which will be compared against the HOG distribution when the person is occluded. The output will become the initial people detection result.

The tracking module leverages the AdaBoost, or Adaptive Boosting, learning algorithm to learn the color appearance of every tracked person, which is computed from the RGB histogram. The machine learning technique will improve the mode over time based on minimizing the errors in the previous models. The tracking module also estimates the motion for each person from their current position using an unscented Kalman Filter with a constant velocity model. Lastly, the system uses a people detector that helps the robot distinguish different people when they are close to each other using color information, as well as keeps it on tracked targets without moving towards obstacles when their colors are similar to those of the targets.

\subsection{Point ensemble image (PEI), histogram of height difference (HOHD), joint histogram of color and height (JHCH)}

Liu et a.\ proposes a number of new techniques for tracking in realtime with a single Kinect sensor~\cite{liu_tracking_with_pei}, namely the point ensemble image (PEI), histogram of height difference (HOHD), and joint histogram of color and height (JHCH). The proposed method is divided into four stages stages. It transforms the RGB-D data into point ensemble images, then uses a detector to find positions of the human body, and finally a feature classifier that uses both histogram of height difference and joint histogram of color and height for fined-grained characterization of the human shape and apperance. Data association of the detection results over time with Kalman Filter is used to generate 3D trajectories for tracking.

A PEI representation combines the person's point cloud with height information. Firstly, the original point cloud of a person is transformed into the plan-view perspective, which is a 2D view of the model's depth data from the top-down perspective. A height map is generated from the point cloud in plan-view perspective. The height map color codes each cell with the highest point value. The final PEI image overlaps the original 3D point cloud with the height map.

In the second stage, the method detects human bodies from the generated PEI in two steps. Similarly to Munaro et al.\'s appraoch, they find the local maxima points representing the head and draw a cylindrical boundary with radius $\omega/2$, where $\omega$ is the average width of the human torso. The points are selected with a constraint specifying the minimum and maximum height, thus filtering out a large amount of unfeasible points. Later on, the method tests whether the potential bodies are indeed humans using a shape and appearance classifier with data extracted from the neighboring points of the potential head position.

The features used in the classifier are HOHD and JHCH. HOHD leverages the information that the height of the head crown is larger than other points on the head and points around the shoulder. The height difference between the head and shoulder is less than a quarter of the average human height. JHCH analyzes the color and height distribution of the human head. The method examines the probability distribution of the skin and hair color with respect to height for neighboring points around the head whose height values are within the average length of the human head. Normally, the probability of the skin color occurrence decreases as the probability of the hair color increases.

The tracking algrorithm takes the surving points in PEI from the current frame as input and returns the association result with the current tracks as output. The color similarity is computed from the JHCH, and the spatial position similarity is computed from difference between the actual position and predicted position using Kalman Filter. The algorithm labels detection results which have have no corresponding tracks as new tracked targets in the scene.

  % \item 
  % \item Applications for a people detection and tracking algorithm using a time-of-flight camera
  % \item Real-time Human Motion Tracking using Multiple Depth Cameras
  % \item Human Detection Using Depth Information by Kinect

\section{Coordinate Transformation}


\cite{eggert_four_algorithms}
\cite{horn_unit_quaternions}
\cite{wei_kinect_calibration}


\section{Limitations of Related Work}

\end{document}
