
\begin{document}

\chapter{Background}

\label{chapter:background}

This chapter will review the the state of the art people detection and tracking techniques.

Tracking by detection is a popular approach to tracking objects in complex environments. A tracking by detection algorithm would detect interested objects in every frame update, thus updating the tracks in the internal of the algorithm. Tracking based on correlation or changed-based matching between frames introduces new challenges, such as stochastic movements, sensor noise, illumination changes, cluttered and dynamic backgrounds, and occlusion. Current tracking methods combine this simple approach and predictions about object trajectory to achieve better results. Kalman Filter is the fundamental building block of many tracking algorithms for predicting the states of the objects in the scene. Other variations of the Kalman Filter include the Extended Kalman Filter~\cite{ljung_extended_kalman} and Unscented Kalman Filter~\cite{julier_unscented_kalman}.

The problem of people detection and tracking has been researched extensively in surveillance video, using techniques such as particle filters~\cite{sherrah_particle_filter_video_surveillance}, background subtraction techniques and color histograms~\cite{mckenna_tracking_groups_of_people}, 3D pose estimation~\cite{andriluka_3d_pose_estimation_tracking}, occlusion-aware people detectors~\cite{tang_people_dectector}, and clustering the motion paths of local features~\cite{gudys_cluster_local_features}.

With the advent of inexpensive, time-of-flight cameras like the Kinect, various tracking algorithms have taken the advantage of high frame rates depth and RGB data. They are portable and easily deployable in real world environments.

\section{Tracking with Color and Depth Data}

Tracking with RGB-D cameras such as the Kinect usually uses both the color and depth information. In general, color information is great at distinguishing people who look somewhat different, using local features or gradient orientations from different body regions. However, color information can fail to track people when they share similar colors. In such cases, depth information can provide another solution by segmenting a cluster of people based on their depth values and the derived height values. This is important because people may not have persistence color and texture when they move about in the environment or interact with others. Despite the differences, tracking using color or depth data usually makes the same assumption that the same object in successive frames will have similar colors and positions (small changes in velocity). The following section will review some common techniques in tracking using color and depth information.

Color normalization and histograms are common techniques in RGB-based tracking. The distribution of color values in an image may change accordingly to the illumination level in the environment when the image was taken. Color normalization can mitigate this unwanted effect~\cite{reinhard_color_transfers}. Some studies use other color spaces for tracking purposes. For instance, Liu et al.\ uses the hue component in the HSV color space to minimize the effects of illumination~\cite{liu_tracking_with_pei}.

Color histograms represent an image by showing the the amount of pixels each range of color values occupies in that image. Correlation or intersection of two histograms can be used in similarity matching between tracks. In particular, histogram of oriented gradients (HOG) is a power feature descriptor for tracking similar targets~\cite{dalal_hog, dollar_pedestrian_detection, munaro_tracking_within_groups_with_mobile_robot, luber_rgbd_boosted_models}. An image gradient is a directional change in the color intensity of a fixed-size detection window. Each detection window is divided into cells. A local histogram of gradient directions is created for each cell, hence local features can be characterized by the distribution of the local gradients. The descriptor can be used to train a linear Support Vector Machine (SVM) to do person and non-person classification, as well as to detect multiple people with a discriminative appearance model.

Depth-based tracking makes detection decisions based on the technique of segmentation. It classify the depth map into regions of the same depth value, allowing further algorithms to do human detection on the clusters. Depth data can be used like color data, such as extracting similarity features from local depth histograms~\cite{ikemura_depth_simialrity_features} and gradient changes in depth map~\cite{spinello_depth_gradients}.

Plagemann et al.\ proposes an interest point detector for localizing human body parts from depth images~\cite{plagemann_body_from_depth}. Interests points are points on the images that are invariant to movements and noise over time, meaning that they represent actual points on the potential human body. The proposed algorithm estimates the orientation of the interest points and normalizes the points according to that orientation. As mentioned earlier, these interest points are potential human body parts. A classifier learns to assign descriptors to the same interests points using training data from a marker-based motion capture system.

Xie et al.\ proposes a similar method ~\cite{xia_2d_depth_3d_model}. Instead of points, the algorithm uses edges in the depth map to find potential regions containing a human body. A predefined head template is used to match against those regions by positioning the template at various locations. The region is verified as a human body if a constructed 3D model around that region matches against predefined 3D head models. A region growing algorithm is then applied to extract the whole body contours. Tracking is performed by matching body contours those have the least ``energy score'', calculated using the changes in coordinates.

\section{Tracking with Kinect}

This section describes a number of different methodologies of tracking people using the Kinect in recent research. The proposed methods use a combination of RGB and depth based tracking techniques to achieve better results.

\subsection{Subclustering and appearance classifiers}

Munaro et al.\ proposes a people tracking algorithm for mobile robots using depth sensor information~\cite{munaro_tracking_within_groups_with_mobile_robot, munaro_tracking_2}. The proposed algorithm performs clustering on the scene for initial detection, then uses Kalman filter on the motion and appearance features to track multiple people within groups. The method assumes people are on the ground plane.

Initially, the method reduces the size of the Kinect depth point cloud through voxel grid filtering. The process divides the depth map into voxels, where the value of each voxel is the averaged depth value over an area. Then, depth clustering is used to segment the scene into potential people with different heights. Sub clusters are created by finding the local maxima inside the entire cluster, where each sub-cluster is a bounding box enclosing a person's body. A HOG confidence is calculated for every sub-cluster, which will be compared against the HOG distribution when the person is occluded. The output will become the initial people detection result.

The tracking module leverages the AdaBoost, or Adaptive Boosting, learning algorithm to learn the color appearance of every tracked person, which is computed from the RGB histogram. The machine learning technique will improve the mode over time based on minimizing the errors in the previous models. The tracking module also estimates the motion for each person from their current position using an unscented Kalman Filter with a constant velocity model. Lastly, the system uses a people detector that helps the robot distinguish different people when they are close to each other using color information, as well as keeps it on tracked targets without moving towards obstacles when their colors are similar to those of the targets.

\subsection{Point ensemble image (PEI), histogram of height difference (HOHD), joint histogram of color and height (JHCH)}

Liu et al.\ proposes a number of new techniques for tracking in realtime with a single Kinect sensor~\cite{liu_tracking_with_pei}, namely the point ensemble image (PEI), histogram of height difference (HOHD), and joint histogram of color and height (JHCH). The proposed method is divided into four stages stages. It transforms the RGB-D data into point ensemble images, then uses a detector to find positions of the human body, and finally a feature classifier that uses both histogram of height difference and joint histogram of color and height for fined-grained characterization of the human shape and appearance. Data association of the detection results over time with Kalman Filter is used to generate 3D trajectories for tracking.

A PEI representation combines the person's point cloud with height information. Firstly, the original point cloud of a person is transformed into the plan-view perspective, which is a 2D view of the model's depth data from the top-down perspective. A height map is generated from the point cloud in plan-view perspective. The height map color codes each cell with the highest point value. The final PEI image overlaps the original 3D point cloud with the height map.

In the second stage, the method detects human bodies from the generated PEI in two steps. Similarly to Munaro et al.\'s approach, they find the local maxima points representing the head and draw a cylindrical boundary with radius $\omega/2$, where $\omega$ is the average width of the human torso. The points are selected with a constraint specifying the minimum and maximum height, thus filtering out a large amount of unfeasible points. Later on, the method tests whether the potential bodies are indeed humans using a shape and appearance classifier with data extracted from the neighboring points of the potential head position.

The features used in the classifier are HOHD and JHCH. HOHD leverages the information that the height of the head crown is larger than other points on the head and points around the shoulder. The height difference between the head and shoulder is less than a quarter of the average human height. JHCH analyzes the color and height distribution of the human head. The method examines the probability distribution of the skin and hair color with respect to height for neighboring points around the head whose height values are within the average length of the human head. Normally, the probability of the skin color occurrence decreases as the probability of the hair color increases.

The tracking algorithm takes the ``surviving points'' in PEI from the current frame as input and returns the association result with the current tracks as output. The color similarity is computed from the JHCH, and the spatial position similarity is computed from difference between the actual position and predicted position using Kalman Filter. The algorithm labels detection results which have have no corresponding tracks as new tracked targets in the scene.

% \subsection{}

  % \item **Real-time Human Motion Tracking using Multiple Depth Cameras
  % \item 
  % \item Applications for a people detection and tracking algorithm using a time-of-flight camera
  % \item Human Detection Using Depth Information by Kinect
% \itemA General Framework for Tracking Multiple People from a Moving Camera
% Tracking People across Multiple Non-Overlapping RGB-D Sensors
% Context-Aware 3D Gesture Interaction Based on Multiple Kinects

\subsection{Coordinate Transformation}

Eggert et al.\ surveyed four techniques for 3D rigid body transformations~\cite{eggert_four_algorithms}, namely singular value decomposition, orthonormal matrices, unit quaternions, and dual quaternions. The current work is based on unit quaternions proposed by Horn~\cite{horn_unit_quaternions}, which represents the translational, scale, and rotational offsets between two coordinate systems in a $4x4$ matrix.

Wei et al.~\cite{wei_kinect_calibration} and Caon et al.~\cite{caon_context_aware_gesture} use unit quaternions to transform two Kinect coordinate systems. The current work uses the same method, which will be discussed in chapter~\ref{chapter:current_approach}. The method is preferred because of ease of implementation, which facilitates fast development cycle for the project in a limited time frame.

\section{Limitations of Related Work}

The main limitation of the research described is that the joint positions of a person are not readily accessible during occlusion. The existing algorithms are good at tracking people in complex environments and retracting them after occlusion, but spatial and visual information about the people during occlusion are limited and almost non-existent~\cite{munaro_tracking_within_groups_with_mobile_robot}. In addition, the same person appearing after occlusion will have a different tracking id~\cite{liu_tracking_with_pei}. Multiple Kinects will provide a larger field of view, allowing the system to track the occluded person' movements when they are outside the viewing angle of a single sensor. Previous research has shown promising tracking results using multiple cameras in both overlapping ~\cite{zhang_multiple_depth_cameras, chu_multiple_cameras_transfer_functions, yildiz_multiple_cameras_constraints, yamashita_multiple_cameras_face_detection} and non-overlapping views~\cite{cai_intercamera_context_tracking, javed_tracking_disjoint}. However, these findings have not discussed persistent joint, or body region, tracking during one camera partial occlusion.

\end{document}
